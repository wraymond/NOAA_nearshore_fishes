---
title: "Analysis_model_building"
author: "Wendel Raymond"
date: "October 1, 2018"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Model building
Using the data prepared from the data preparation script we can now beging model building. Before we can run a PERMANOVA we will need to prep the response and explanatory data. After that we will generate a global model and eventually best model, testing the effect of habitat on fish community composition.

```{r data}
dat <- read.csv("Data/SEAK_EventID_mass.csv", header = TRUE, stringsAsFactors = TRUE)
```

```{r libraries}
library(dplyr)
library(tidyr)
library(vegan)
library(ggplot2)
theme_set(theme_classic())
```

## Exploring the data
```{r explor}
dat.sum <- dat %>%
  group_by(EventID, SpCode) %>% 
  summarise(SpSum = sum(mass_g))
  
ggplot(dat.sum) +
  geom_histogram(aes(SpSum)) +
  facet_wrap(~SpCode)
```


## Prepping response and explanatory data
For ease of processing later we will separate the response data (species and mass) from the explanatory data (EventID, date, month, temp, salinity, etc.). I separate the site level characteristic data like habitat, temp, salinity, lat/long from the species and mass data. Then I will `spread` the mass data so that species are columns and EventIDs are rows. 

```{r separating}
## Species filtering ##
dat.filt <- dat %>% 
  filter(SpCode != "PINKSAL" & SpCode != "CHINSAL" & SpCode != "CHUMSAL" & SpCode != "COHOSAL" & SpCode != "SOCKSAL" & SpCode != "POLLOCK" & SpCode != "PSANDL" & SpCode != "HERRING")

## Site data ##
names(dat.filt)
site <- unique(dat.filt[, c(1, 3:17)])
duplicated(site$EventID)

## Fish data ##
fish <- dat.filt[, c(1, 2, 18)]
duplicated(fish)
fish <- spread(fish, SpCode, mass_g)
fish[is.na(fish)] <- 0
colSums(fish) # UNLARV has no data whatsoever
fish <- fish[, c(1:76, 78:89)] # removing UNLARV
```

## Data filtering
There is a large range of data in terms of presense/absense and biomass. This large range of values that have highly skewed distributions will mess with interpretation of our multivariate response. What follows are some filtering procedures to try to control extreme values.

### Remove rare species
For this filtering I will remove species that occur in less that 1% of seines. These species can be thought of as exceedingly rare. This will be done by converining mass to presence/absence and calculating relative fequency of occurance across all seines. 
```{r remove rare}
## Covnert to P/A ##
fish.pa <- ifelse(fish[,2:88] > 0, 1, 0)
fish.pa <- data.frame(cbind(EventID = fish$EventID), fish.pa)

## Calculate species totals ##
sp.total <- colSums(fish.pa[,2:88])

## Calculate freq of occurance ##
sp.fq <- (sp.total/nrow(fish)) * 100

## Rare species ##
rare.sp <- ifelse(sp.fq < 1, names(sp.fq), NA)
rare.sp <- rare.sp[!is.na(rare.sp)]

## Filter out rare speces ##
fish <- fish[, -which(names(fish) %in% names(rare.sp))]
```

### Removing hyper and hypo abundant Events
First we need to calculate the total fish catch at each site and plot. I will plot raw and 4th root transformed data and log stransformed.
```{r event sums}
## EventID sums ##
event.sum <- data.frame(EventID = fish$EventID,
                        Sum = rowSums(fish[, 2:60]))
## Plots ##
# Box plots #
ggplot(event.sum) +
  geom_boxplot(aes(x = EventID, y = Sum))

ggplot(event.sum) +
  geom_boxplot(aes(x = EventID, y = (Sum)^0.25))

ggplot(event.sum) +
  geom_boxplot(aes(x = EventID, y = log(Sum, base = 10)))

# Histograms #
ggplot(event.sum) +
  geom_histogram(aes(Sum))

ggplot(event.sum) +
  geom_histogram(aes((Sum)^.25))

ggplot(event.sum) +
  geom_histogram(aes(log(Sum, base = 10)))

quantile(log(event.sum$Sum, base = 10), probs = c(0.025, 0.975))
```

I will filter out Events that with total catches outside 2 standard deviations of the average catch
```{r}
filt <- event.sum %>%
  filter(log(Sum, base = 10) > 0.5766482 & log(Sum, base = 10) < 4.2300721)

ggplot(filt) +
  geom_histogram(aes(log(Sum, 10)))

fish <- subset(fish, fish$EventID %in% filt$EventID)
```


### Transformations
This step could be considered optional, however, when looking at the data there are quite a few species with long right tail distributions. I will use a log transformation becasue the data are HIGHLY skewed. 
```{r transformations}
## Transform ##
fish.trsfm <- data.frame(log(fish[, 2:60], base = 10))

## Convert Inf to Zero ##
fish.trsfm[mapply(is.infinite, fish.trsfm)] <- 0
```

### Standarization
I will use a double standardization to 
1. standardize to species maximum
2. then standarize to total mass
```{r standardization}
## To species maximum ##
fish.std <- scale(fish.trsfm, center = FALSE, scale = apply(fish.trsfm, 2, max))

## To EventID total ##
fish.std <- fish.std/rowSums(fish.trsfm)
```

## Dissimilarity
Calculate dissimilarity matrix in preparation for PERMANOVA. I will use bray-curtis method as is recommended for non-multivariate normal data
```{r dissim}
dist.bray <- vegdist(fish.std, method = "bray")

## Assign row names as event ID ##
row.names(mds$points) <- fish$EventID
```

## PCA
There are a few variablibes that are driving the dissimilarity
```{r}
pca <- princomp(dist.bray)
summary(pca)
biplot(pca, cex = .5)
```


### NMDS
```{r nmds}
mds <- metaMDS(dist.bray)
mds.xy <- data.frame(mds$points)
mds.xy$EventID <- fish$EventID
mds.xy <- merge(mds.xy, site, by = "EventID", all.x = TRUE)


ggplot(mds.xy) +
  geom_point(aes(MDS1, MDS2, color = month))
```


## Model - PERMANOVA
```{r perm}
mod1 <- adonis2(dist.bray ~ habitat + month + temp_c, data = mds.xy, permutations = 9999)
mod1
```

